{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Column_Selector():\n",
    "    \n",
    "    file_path = str(input(\"Input file name or path: \"))\n",
    "    \n",
    "    load_excel = pd.ExcelFile(file_path)\n",
    "    \n",
    "    print(\"Sheets available in this file: \", load_excel.sheet_names)\n",
    "    \n",
    "    sheet_name = str(input(\"Which sheet would you like to access?: \"))\n",
    "    \n",
    "    overall_df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "        \n",
    "    print(\"These are the columns in this file: \", list(overall_df))\n",
    "    \n",
    "    select_columns = input(\"Which columns would you like to select? Type in name of column separated by a comma. (e.g. Default Weights, Q136): \")\n",
    "    \n",
    "    column_list = select_columns.replace(\", \",\",\").split(\",\")\n",
    "    \n",
    "    temp_df = overall_df[column_list]\n",
    "    \n",
    "    for i in column_list:\n",
    "        rename = str(input(f'What would you like to rename {i}: '))\n",
    "        temp_df.rename(columns = {i:rename}, inplace = True)\n",
    "    \n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Creative_Selector(dataframe):\n",
    "    \n",
    "    if isinstance(dataframe, pd.DataFrame):\n",
    "        print(\"These are the columns in this file: \", list(dataframe))\n",
    "        creative_column = str(input(\"Which is the creative column?: \"))\n",
    "        if creative_column not in list(dataframe):\n",
    "            return \"That column is not in the dataframe!\"\n",
    "        else:\n",
    "            dataframe.rename(columns={creative_column:'Creative'}, inplace=True)\n",
    "            dataframe_group = dict(tuple(dataframe.groupby('Creative')))\n",
    "            creative_list = dataframe.Creative.unique()\n",
    "            print(\"There are the unique creatives in this dataset: \", list(creative_list))\n",
    "            selected_creative = str(input(\"Which creative would you like to analyze?: \"))\n",
    "            selected_creative_df =  dataframe_group[selected_creative]     \n",
    "            return selected_creative_df\n",
    "    else:\n",
    "        return print(\"You have not passed a pandas dataframe to the function!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file name or path: Nest_US_Video_Verbatims_Q2-Q4.xlsx\n",
      "Sheets available in this file:  ['Q2 2019 - 19Q2_015 (1)', 'Q2 2019 - 19Q2_015 (2)', 'Q3 2019 - 19Q2_016', 'Q3 2019 - 12Q3_011', 'Q4 2019 - 19Q3_076', 'Q4 2019 - 19Q4_011', 'Q4 2019 - 19Q4_026', 'Q4 2019 - 19Q4_044', 'Q4 2019 - 19Q4_059']\n",
      "Which sheet would you like to access?: Q4 2019 - 19Q4_059\n",
      "These are the columns in this file:  ['Creative', 'Q170', 'Q171', 'Q172']\n",
      "Which columns would you like to select? Type in name of column separated by a comma. (e.g. Default Weights, Q136): Creative, Q170\n",
      "What would you like to rename Creative: Creative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\showmik.podder\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4025: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What would you like to rename Q170: Takeaways\n",
      "These are the columns in this file:  ['Creative', 'Takeaways']\n",
      "Which is the creative column?: Creative\n",
      "There are the unique creatives in this dataset:  ['(C) Frozen Stories', '(B) Frozen Read Along', '(A) Control']\n",
      "Which creative would you like to analyze?: (C) Frozen Stories\n"
     ]
    }
   ],
   "source": [
    "Frozen_Stories = Creative_Selector(Column_Selector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Frozen_Stories.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "count_vect = CountVectorizer(stop_words='english')\n",
    "takeaways_matrix = count_vect.fit_transform(Frozen_Stories['Takeaways'].values.astype('U'))\n",
    "tfidf_vect = TfidfVectorizer(stop_words='english')\n",
    "takeaways_matrix_tfidf = tfidf_vect.fit_transform(Frozen_Stories['Takeaways'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<250x263 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 731 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "takeaways_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='batch', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_components=5, n_jobs=None, n_topics=None, perp_tol=0.1,\n",
       "             random_state=42, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA.fit(takeaways_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_topic = LDA.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_topic_words = first_topic.argsort()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "touch\n",
      "story\n",
      "children\n",
      "watch\n",
      "disney\n",
      "kids\n",
      "good\n",
      "nan\n",
      "easy\n",
      "use\n"
     ]
    }
   ],
   "source": [
    "for i in top_topic_words:\n",
    "    print(count_vect.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0:\n",
      "['touch', 'story', 'children', 'watch', 'disney', 'kids', 'good', 'nan', 'easy', 'use']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['helpful', 'want', 'kids', 'friendly', 'device', 'great', 'story', 'things', 'know', 'don']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['characters', 'children', 'movie', 'kids', 'makes', 'easier', 'life', 'tell', 'frozen', 'stories']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['fun', 'mini', 'home', 'stories', 'ask', 'sure', 'product', 'frozen', 'nest', 'google']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4:\n",
      "['com', 'mind', 'brands', 'way', 'use', 'technology', 'home', 'smart', 'easy', 'family']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,topic in enumerate(LDA.components_):\n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([count_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='batch', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_components=5, n_jobs=None, n_topics=None, perp_tol=0.1,\n",
       "             random_state=42, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA2 = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA2.fit(takeaways_matrix_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0:\n",
      "['children', 'convenient', 'friendly', 'like', 'watch', 'kids', 'good', 'nan', 'use', 'easy']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['love', 'try', 'helpful', 'great', 'story', 'things', 'stories', 'don', 'know', 'tell']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['kids', 'children', 'tells', 'tell', 'movie', 'frozen', 'easier', 'makes', 'stories', 'life']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['read', 'exclusive', 'fun', 'ask', 'nest', 'product', 'stories', 'google', 'sure', 'frozen']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4:\n",
      "['entertainment', 'camera', 'mini', 'good', 'way', 'smart', 'google', 'home', 'technology', 'family']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,topic in enumerate(LDA2.components_):\n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([tfidf_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
       "  n_components=5, random_state=42, shuffle=False, solver='cd', tol=0.0001,\n",
       "  verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf = NMF(n_components=5, random_state=42)\n",
    "nmf2 = NMF(n_components=5, random_state=42)\n",
    "nmf.fit(takeaways_matrix)\n",
    "nmf2.fit(takeaways_matrix_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0:\n",
      "['just', 'great', 'kids', 'ask', 'touch', 'disney', 'nest', 'google', 'tell', 'stories']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['time', 'story', 'family', 'good', 'kids', 'brands', 'com', 'come', 'mind', 'lot']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['gain', 'favorite', 'children', 'fun', 'hear', 'convenient', 'family', 'kids', 'use', 'easy']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['content', 'mini', 'information', 'story', 'voices', 'listen', 'characters', 'movie', 'stories', 'frozen']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4:\n",
      "['don', 'help', 'product', 'entertain', 'things', 'make', 'home', 'makes', 'easier', 'life']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,topic in enumerate(nmf.components_):\n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([count_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0:\n",
      "['ad', 'taking', 'watch', 'content', 'exclusive', 'story', 'listen', 'disney', 'movie', 'frozen']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['hear', 'children', 'kids', 'fairly', 'things', 'family', 'helpful', 'convenient', 'use', 'easy']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['story', 'characters', 'read', 'tells', 'kids', 'ask', 'google', 'nest', 'tell', 'stories']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['entertain', 'making', 'things', 'family', 'make', 'product', 'home', 'easier', 'makes', 'life']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4:\n",
      "['product', 'mini', 'google', 'used', 'entertainment', 'friendly', 'kids', 'good', 'family', 'nan']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,topic in enumerate(nmf2.components_):\n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([tfidf_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Topic_Modeler(dataframe):\n",
    "    verbatim = input(\"Which verbatim column would you like to analyze?:\")\n",
    "    \n",
    "    dataframe[str(verbatim)]\n",
    "    tfidf_vect = TfidfVectorizer(stop_words='english')\n",
    "    verbatim_matrix_tfidf = tfidf_vect.fit_transform(dataframe[str(verbatim)].values.astype('U'))\n",
    "    components = input(\"How many topics would you like to split this into? \")\n",
    "    nmf = NMF(n_components=int(components), random_state=42)\n",
    "    \n",
    "    nmf.fit(verbatim_matrix_tfidf)\n",
    "    \n",
    "    for i,topic in enumerate(nmf.components_):\n",
    "        print(f'Top 10 words for topic #{i}:')\n",
    "        print([tfidf_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "        print('\\n')\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file name or path: Nest_US_Video_Verbatims_Q2-Q4.xlsx\n",
      "Sheets available in this file:  ['Q2 2019 - 19Q2_015 (1)', 'Q2 2019 - 19Q2_015 (2)', 'Q3 2019 - 19Q2_016', 'Q3 2019 - 12Q3_011', 'Q4 2019 - 19Q3_076', 'Q4 2019 - 19Q4_011', 'Q4 2019 - 19Q4_026', 'Q4 2019 - 19Q4_044', 'Q4 2019 - 19Q4_059']\n",
      "Which sheet would you like to access?: Q4 2019 - 19Q4_059\n",
      "These are the columns in this file:  ['Creative', 'Q170', 'Q171', 'Q172']\n",
      "Which columns would you like to select? Type in name of column separated by a comma. (e.g. Default Weights, Q136): Creative, Q171\n",
      "What would you like to rename Creative: Creative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\showmik.podder\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4025: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What would you like to rename Q171: Dislikes\n",
      "These are the columns in this file:  ['Creative', 'Dislikes']\n",
      "Which is the creative column?: Creative\n",
      "There are the unique creatives in this dataset:  ['(C) Frozen Stories', '(B) Frozen Read Along', '(A) Control']\n",
      "Which creative would you like to analyze?: (B) Frozen Read Along\n"
     ]
    }
   ],
   "source": [
    "Frozen_Read_Along = Creative_Selector(Column_Selector())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which verbatim column would you like to analyze?:Dislikes\n",
      "How many topics would you like to split this into? 5\n",
      "Top 10 words for topic #0:\n",
      "['used', 'involving', 'included', 'advertising', 'theme', 'involved', 'new', 'ad', 'movie', 'frozen']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['movie', 'kids', 'fact', 'stories', 'music', 'story', 'read', 'nice', 'great', 'nan']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['works', 'easy', 'movie', 'wasn', 'long', 'ad', 'look', 'features', 'product', 'like']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['story', 'nice', 'frozen', 'different', 'use', 'appealing', 'fun', 'feauted', 'liked', 'characters']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4:\n",
      "['tell', 'mini', 'special', 'involved', 'story', 'home', 'google', 'nest', 'don', 'know']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Topic_Modeler(Frozen_Read_Along)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
